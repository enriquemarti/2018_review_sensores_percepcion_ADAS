% This file was created with JabRef 2.10.
% Encoding: UTF-8


@InProceedings{Bak2012,
  Title                    = {Multi-sensor localization - Visual Odometry as a low cost proprioceptive sensor},
  Author                   = {Bak, Adrien and Gruyer, Dominique and Bouchafa, Samia and Aubert, Didier},
  Booktitle                = {2012 15th International IEEE Conference on Intelligent Transportation Systems},
  Year                     = {2012},
  Month                    = {sep},
  Pages                    = {1365--1370},
  Publisher                = {IEEE},

  Doi                      = {10.1109/ITSC.2012.6338771},
  ISBN                     = {978-1-4673-3063-3},
  Url                      = {http://ieeexplore.ieee.org/document/6338771/}
}

@Article{Besbes2015,
  Title                    = {Pedestrian detection in far-infrared daytime images using a hierarchical codebook of SURF},
  Author                   = {Besbes, Bassem and Rogozan, Alexandrina and Rus, Adela Maria and Bensrhair, Abdelaziz and Broggi, Alberto},
  Journal                  = {Sensors (Switzerland)},
  Year                     = {2015},

  Month                    = {apr},
  Number                   = {4},
  Pages                    = {8570--8594},
  Volume                   = {15},

  Abstract                 = {One of the main challenges in intelligent vehicles concerns pedestrian detection for driving assistance. Recent experiments have showed that state-of-the-art descriptors provide better performances on the far-infrared (FIR) spectrum than on the visible one, even in daytime conditions, for pedestrian classification. In this paper, we propose a pedestrian detector with on-board FIR camera. Our main contribution is the exploitation of the specific characteristics of FIR images to design a fast, scale-invariant and robust pedestrian detector. Our system consists of three modules, each based on speeded-up robust feature (SURF) matching. The first module allows generating regions-of-interest (ROI), since in FIR images of the pedestrian shapes may vary in large scales, but heads appear usually as light regions. ROI are detected with a high recall rate with the hierarchical codebook of SURF features located in head regions. The second module consists of pedestrian full-body classification by using SVM. This module allows one to enhance the precision with low computational cost. In the third module, we combine the mean shift algorithm with inter-frame scale-invariant SURF feature tracking to enhance the robustness of our system. The experimental evaluation shows that our system outperforms, in the FIR domain, the state-of-the-art Haar-like Adaboost-cascade, histogram of oriented gradients (HOG)/linear SVM (linSVM) and MultiFtrpedestrian detectors, trained on the FIR images.},
  Doi                      = {10.3390/s150408570},
  File                     = {:D$\backslash$:/Users/109123/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Besbes et al. - 2015 - Pedestrian Detection in Far-Infrared Daytime Images Using a Hierarchical Codebook of SURF.pdf:pdf},
  ISSN                     = {14248220},
  Keywords                 = {Far-infrared images,Hierarchical codebook,Pedestrian classification and trackings,Pedestrian detection,SURF,SVM,Scale-invariant feature matching},
  Pmid                     = {25871724},
  Publisher                = {Multidisciplinary Digital Publishing Institute},
  Url                      = {http://www.mdpi.com/1424-8220/15/4/8570/}
}

@Article{CastilloAguilar2015,
  Title                    = {Robust road condition detection system using in-vehicle standard sensors},
  Author                   = {{Castillo Aguilar}, Juan Jes{\'{u}}s and {Cabrera Carrillo}, Juan Antonio and {Guerra Fern{\'{a}}ndez}, Antonio Jes{\'{u}}s and {Carabias Acosta}, Enrique},
  Journal                  = {Sensors (Switzerland)},
  Year                     = {2015},

  Month                    = {dec},
  Number                   = {12},
  Pages                    = {32056--32078},
  Volume                   = {15},

  Abstract                 = {The appearance of active safety systems, such as Anti-lock Braking System, Traction Control System, Stability Control System, etc., represents a major evolution in road safety. In the automotive sector, the term vehicle active safety systems refers to those whose goal is to help avoid a crash or to reduce the risk of having an accident. These systems safeguard us, being in continuous evolution and incorporating new capabilities continuously. In order for these systems and vehicles to work adequately, they need to know some fundamental information: the road condition on which the vehicle is circulating. This early road detection is intended to allow vehicle control systems to act faster and more suitably, thus obtaining a substantial advantage. In this work, we try to detect the road condition the vehicle is being driven on, using the standard sensors installed in commercial vehicles. Vehicle models were programmed in on-board systems to perform real-time estimations of the forces of contact between the wheel and road and the speed of the vehicle. Subsequently, a fuzzy logic block is used to obtain an index representing the road condition. Finally, an artificial neural network was used to provide the optimal slip for each surface. Simulations and experiments verified the proposed method.},
  Doi                      = {10.3390/s151229908},
  File                     = {:D$\backslash$:/Users/109123/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Castillo Aguilar et al. - 2015 - Robust Road Condition Detection System Using In-Vehicle Standard Sensors.pdf:pdf},
  ISSN                     = {14248220},
  Keywords                 = {Friction estimation,Normal driving,Optimal slip estimation,Standard vehicle sensor},
  Pmid                     = {26703605},
  Publisher                = {Multidisciplinary Digital Publishing Institute},
  Url                      = {http://www.mdpi.com/1424-8220/15/12/29908}
}

@Article{chen2017turn,
  Title                    = {Turn signal detection during nighttime by CNN detector and perceptual hashing tracking},
  Author                   = {Chen, Long and Hu, Xuemin and Xu, Tong and Kuang, Hulin and Li, Qingquan},
  Journal                  = {IEEE Transactions on Intelligent Transportation Systems},
  Year                     = {2017},
  Number                   = {12},
  Pages                    = {3303--3314},
  Volume                   = {18},

  Publisher                = {IEEE}
}

@Article{coronado2012detection,
  Title                    = {Detection and classification of road signs for automatic inventory systems using computer vision},
  Author                   = {Coronado, Gustavo A Pel{\'a}ez and Mu{\~n}oz, Mar{\'\i}a Romero and Armingol, Jos{\'e} Mar{\'\i}a and de la Escalera, Arturo and Mu{\~n}oz, Juan Jes{\'u}s and van Bijsterveld, Wouter and Bola{\~n}o, Juan Antonio},
  Journal                  = {Integrated Computer-Aided Engineering},
  Year                     = {2012},
  Number                   = {3},
  Pages                    = {285--298},
  Volume                   = {19},

  Publisher                = {IOS Press}
}

@InProceedings{Dagan2004,
  Title                    = {Forward collision warning with a single camera},
  Author                   = {Dagan, E. and Mano, O. and Stein, G.P. and Shashua, A.},
  Booktitle                = {IEEE Intelligent Vehicles Symposium, 2004},
  Year                     = {2004},
  Pages                    = {37--42},
  Publisher                = {IEEE},

  Abstract                 = {The large number of rear end collisions due to driver inattention has been identified as a major automotive safety issue. Even a short advance warning can significantly reduce the number and severity of the collisions. This paper describes a vision based forward collision warning (FCW) system for highway safety. The algorithm described in this paper computes time to contact (TTC) and possible collision course directly from the size and position of the vehicles in the image - which are the natural measurements for a vision based system - without having to compute a 3D representation of the scene. The use of a single low cost image sensor results in an affordable system which is simple to install. The system has been implemented on real-time hardware and has been test driven on highways. Collision avoidance tests have also been performed on test tracks.},
  Doi                      = {10.1109/IVS.2004.1336352},
  ISBN                     = {0-7803-8310-9},
  Url                      = {http://ieeexplore.ieee.org/document/1336352/}
}

@InProceedings{frejlichowski2015application,
  Title                    = {Application of the Polar--Fourier Greyscale Descriptor to the Automatic Traffic Sign Recognition},
  Author                   = {Frejlichowski, Dariusz},
  Booktitle                = {International Conference Image Analysis and Recognition},
  Year                     = {2015},
  Organization             = {Springer},
  Pages                    = {506--513}
}

@InProceedings{gao2015learning,
  Title                    = {Learning local histogram representation for efficient traffic sign recognition},
  Author                   = {Gao, Jinlu and Fang, Yuqiang and Li, Xingwei},
  Booktitle                = {Image and Signal Processing (CISP), 2015 8th International Congress on},
  Year                     = {2015},
  Organization             = {IEEE},
  Pages                    = {631--635}
}

@Article{gargoum2017automated,
  Title                    = {Automated highway sign extraction using lidar data},
  Author                   = {Gargoum, Suliman and El-Basyouny, Karim and Sabbagh, Joseph and Froese, Kenneth},
  Journal                  = {Transportation Research Record: Journal of the Transportation Research Board},
  Year                     = {2017},
  Number                   = {2643},
  Pages                    = {1--8},

  Publisher                = {Transportation Research Board of the National Academies}
}

@InProceedings{gu2011traffic,
  Title                    = {Traffic sign detection in dual-focal active camera system},
  Author                   = {Gu, Yanlei and Yendo, Tomohiro and Tehrani, Mehrdad Panahpour and Fujii, Toshiaki and Tanimoto, Masayuki},
  Booktitle                = {Intelligent Vehicles Symposium (IV), 2011 IEEE},
  Year                     = {2011},
  Organization             = {IEEE},
  Pages                    = {1054--1059}
}

@Article{guan2018robust,
  Title                    = {Robust Traffic-Sign Detection and Classification Using Mobile LiDAR Data With Digital Images},
  Author                   = {Guan, Haiyan and Yan, Wanqian and Yu, Yongtao and Zhong, Liang and Li, Dilong},
  Journal                  = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
  Year                     = {2018},

  Publisher                = {IEEE}
}

@Article{hillel2014recent,
  Title                    = {Recent progress in road and lane detection: a survey},
  Author                   = {Hillel, Aharon Bar and Lerner, Ronen and Levi, Dan and Raz, Guy},
  Journal                  = {Machine vision and applications},
  Year                     = {2014},
  Number                   = {3},
  Pages                    = {727--745},
  Volume                   = {25},

  Publisher                = {Springer}
}

@Article{hosseinyalamdary2017bayesian,
  Title                    = {A Bayesian approach to traffic light detection and mapping},
  Author                   = {Hosseinyalamdary, Siavash and Yilmaz, Alper},
  Journal                  = {ISPRS journal of photogrammetry and remote sensing},
  Year                     = {2017},
  Pages                    = {184--192},
  Volume                   = {125},

  Publisher                = {Elsevier}
}

@InProceedings{Ieng2003,
  Title                    = {Merging lateral cameras information with proprioceptive sensors in vehicle location gives centimetric precision},
  Author                   = {Ieng, S-S and Gruyer, D},
  Booktitle                = {Proceedings of the 18th International Technical Conference on the Enhanced Safety of Vehicles},
  Year                     = {2003},

  Address                  = {Nagoya, Japan},
  Month                    = {may},
  Publisher                = {National Highway Traffic Safety Administration},

  Url                      = {https://trid.trb.org/view.aspx?id=750799}
}

@InProceedings{Janda2013,
  Title                    = {Road boundary detection for run-off road prevention based on the fusion of video and radar},
  Author                   = {Janda, Florian and Pangerl, Sebastian and Lang, Eva and Fuchs, Erich},
  Booktitle                = {IEEE Intelligent Vehicles Symposium, Proceedings},
  Year                     = {2013},
  Month                    = {jun},
  Pages                    = {1173--1178},
  Publisher                = {IEEE},

  Abstract                 = {An approach for detecting the road boundary on different types of roads without any preliminary knowledge is presented. We fuse information obtained from an algorithm which detects road markings and road edges in images acquired by a video camera as well as data from a radar sensor. Each road marking, each road edge and each road barrier is tracked individually. Hence we can even capture exits or laybys. We use an edge image for road marking detection and texture information for road edge detection. Additional data provided by a radar sensor is used to measure targets referring to static barriers along the road side such as guardrails. The output of each processing unit is fused into a Kalman filter framework, where the confidence of each subsystem influences the innovation of the overall system. The underlying geometric road model comprises parameters for multiple lanes, the flanking road edge as well as the vehicle's relative pose. The work is part of the project Interactive.},
  Doi                      = {10.1109/IVS.2013.6629625},
  ISBN                     = {9781467327558},
  ISSN                     = {1931-0587},
  Url                      = {http://ieeexplore.ieee.org/document/6629625/}
}

@Article{kaliyaperumal2001algorithm,
  Title                    = {An algorithm for detecting roads and obstacles in radar images},
  Author                   = {Kaliyaperumal, Kesav and Lakshmanan, Sridhar and Kluge, Karl},
  Journal                  = {IEEE Transactions on Vehicular Technology},
  Year                     = {2001},
  Number                   = {1},
  Pages                    = {170--182},
  Volume                   = {50},

  Publisher                = {IEEE}
}

@InProceedings{kim2015lane,
  Title                    = {Lane map building and localization for automated driving using 2D laser rangefinder},
  Author                   = {Kim, Dongwook and Chung, Taeyoung and Yi, Kyongsu},
  Booktitle                = {Intelligent Vehicles Symposium (IV), 2015 IEEE},
  Year                     = {2015},
  Organization             = {IEEE},
  Pages                    = {680--685}
}

@Article{Koch2011,
  Title                    = {Pothole detection in asphalt pavement images},
  Author                   = {Koch, Christian and Brilakis, Ioannis},
  Journal                  = {Advanced Engineering Informatics},
  Year                     = {2011},

  Month                    = {aug},
  Number                   = {3},
  Pages                    = {507--515},
  Volume                   = {25},

  Abstract                 = {Pavement condition assessment is essential when developing road network maintenance programs. In practice, the data collection process is to a large extent automated. However, pavement distress detection (cracks, potholes, etc.) is mostly performed manually, which is labor-intensive and time-consuming. Existing methods either rely on complete 3D surface reconstruction, which comes along with high equipment and computation costs, or make use of acceleration data, which can only provide preliminary and rough condition surveys. In this paper we present a method for automated pothole detection in asphalt pavement images. In the proposed method an image is first segmented into defect and non-defect regions using histogram shape-based thresholding. Based on the geometric properties of a defect region the potential pothole shape is approximated utilizing morphological thinning and elliptic regression. Subsequently, the texture inside a potential defect shape is extracted and compared with the texture of the surrounding non-defect pavement in order to determine if the region of interest represents an actual pothole. This methodology has been implemented in a MATLAB prototype, trained and tested on 120 pavement images. The results show that this method can detect potholes in asphalt pavement images with reasonable accuracy. {\textcopyright} 2011 Elsevier Ltd. All rights reserved.},
  Doi                      = {10.1016/j.aei.2011.01.002},
  ISBN                     = {1474-0346},
  ISSN                     = {14740346},
  Keywords                 = {Image processing,Pavement assessment,Pothole detection,Visual sensing},
  Publisher                = {Elsevier},
  Url                      = {http://www.sciencedirect.com/science/article/pii/S1474034611000036}
}

@InProceedings{kum2013lane,
  Title                    = {Lane detection system with around view monitoring for intelligent vehicle},
  Author                   = {Kum, Chang-Hoon and Cho, Dong-Chan and Ra, Moon-Soo and Kim, Whoi-Yul},
  Booktitle                = {SoC Design Conference (ISOCC), 2013 International},
  Year                     = {2013},
  Organization             = {IEEE},
  Pages                    = {215--218}
}

@InProceedings{lee2017avm,
  Title                    = {AVM/LiDAR sensor based lane marking detection method for automated driving on complex urban roads},
  Author                   = {Lee, Hyunsung and Kim, Seonwook and Park, Sungyoul and Jeong, Yonghwan and Lee, Hojoon and Yi, Kyongsu},
  Booktitle                = {Intelligent Vehicles Symposium (IV), 2017 IEEE},
  Year                     = {2017},
  Organization             = {IEEE},
  Pages                    = {1434--1439}
}

@InProceedings{li2013new,
  Title                    = {A new 3D LIDAR-based lane markings recognition approach},
  Author                   = {Li, Tan and Zhidong, Deng},
  Booktitle                = {Robotics and Biomimetics (ROBIO), 2013 IEEE International Conference on},
  Year                     = {2013},
  Organization             = {IEEE},
  Pages                    = {2197--2202}
}

@Article{liu2014traffic,
  Title                    = {Traffic sign recognition using group sparse coding},
  Author                   = {Liu, Huaping and Liu, Yulong and Sun, Fuchun},
  Journal                  = {Information Sciences},
  Year                     = {2014},
  Pages                    = {75--89},
  Volume                   = {266},

  Publisher                = {Elsevier}
}

@Article{Liu2015,
  Title                    = {An ultrasonic sensor system based on a two-dimensional state method for highway vehicle violation detection applications},
  Author                   = {Liu, Jun and Han, Jiuqiang and Lv, Hongqiang and Li, Bing},
  Journal                  = {Sensors (Switzerland)},
  Year                     = {2015},

  Month                    = {apr},
  Number                   = {4},
  Pages                    = {9000--9021},
  Volume                   = {15},

  Abstract                 = {With the continuing growth of highway construction and vehicle use expansion all over the world, highway vehicle traffic rule violation (TRV) detection has become more and more important so as to avoid traffic accidents and injuries in intelligent transportation systems (ITS) and vehicular ad hoc networks (VANETs). Since very few works have contributed to solve the TRV detection problem by moving vehicle measurements and surveillance devices, this paper develops a novel parallel ultrasonic sensor system that can be used to identify the TRV behavior of a host vehicle in real-time. Then a two-dimensional state method is proposed, utilizing the spacial state and time sequential states from the data of two parallel ultrasonic sensors to detect and count the highway vehicle violations. Finally, the theoretical TRV identification probability is analyzed, and actual experiments are conducted on different highway segments with various driving speeds, which indicates that the identification accuracy of the proposed method can reach about 90.97{\%}.},
  Doi                      = {10.3390/s150409000},
  File                     = {:D$\backslash$:/Users/109123/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2015 - An Ultrasonic Sensor System Based on a Two-Dimensional State Method for Highway Vehicle Violation Detection Applicat.pdf:pdf},
  ISSN                     = {14248220},
  Keywords                 = {Highway vehicle traffic rule violation detection,Intelligent transportation systems,Two-dimensional state method,Ultrasonic sensor system},
  Pmid                     = {1603305},
  Publisher                = {Multidisciplinary Digital Publishing Institute},
  Url                      = {http://www.mdpi.com/1424-8220/15/4/9000/}
}

@Article{Lundquist2011,
  Title                    = {Joint ego-motion and road geometry estimation},
  Author                   = {Lundquist, Christian and Sch{\"{o}}n, Thomas B.},
  Journal                  = {Information Fusion},
  Year                     = {2011},

  Month                    = {oct},
  Number                   = {4},
  Pages                    = {253--263},
  Volume                   = {12},

  Abstract                 = {We provide a sensor fusion framework for solving the problem of joint ego-motion and road geometry estimation. More specifically we employ a sensor fusion framework to make systematic use of the measurements from a forward looking radar and camera, steering wheel angle sensor, wheel speed sensors and inertial sensors to compute good estimates of the road geometry and the motion of the ego vehicle on this road. In order to solve this problem we derive dynamical models for the ego vehicle, the road and the leading vehicles. The main difference to existing approaches is that we make use of a new dynamic model for the road. An extended Kalman filter is used to fuse data and to filter measurements from the camera in order to improve the road geometry estimate. The proposed solution has been tested and compared to existing algorithms for this problem, using measurements from authentic traffic environments on public roads in Sweden. The results clearly indicate that the proposed method provides better estimates. ?? 2011 Elsevier B.V. All rights reserved.},
  Doi                      = {10.1016/j.inffus.2010.06.007},
  ISBN                     = {1566-2535},
  ISSN                     = {15662535},
  Keywords                 = {Bicycle model,Extended Kalman filter,Road geometry estimation,Sensor fusion,Single track model},
  Url                      = {http://linkinghub.elsevier.com/retrieve/pii/S1566253510000709}
}

@Article{ma2000simultaneous,
  Title                    = {Simultaneous detection of lane and pavement boundaries using model-based multisensor fusion},
  Author                   = {Ma, Bing and Lakshmanan, Sridhar and Hero, Alfred O},
  Journal                  = {IEEE Transactions on Intelligent Transportation Systems},
  Year                     = {2000},
  Number                   = {3},
  Pages                    = {135--147},
  Volume                   = {1},

  Publisher                = {IEEE}
}

@Article{miyata2017automatic,
  Title                    = {Automatic Recognition of Speed Limits on Speed-Limit Signs by Using Machine Learning},
  Author                   = {Miyata, Shigeharu},
  Journal                  = {Journal of Imaging},
  Year                     = {2017},
  Number                   = {3},
  Pages                    = {25},
  Volume                   = {3},

  Publisher                = {Multidisciplinary Digital Publishing Institute}
}

@Article{Nguyen2013,
  Title                    = {1-Point Ransac Based Robust Visual Odometry},
  Author                   = {Nguyen, Van Cuong and Heo, Moon Beom and Jee, Gyu-In},
  Journal                  = {Journal of Positioning, Navigation, and Timing},
  Year                     = {2013},

  Month                    = {apr},
  Number                   = {1},
  Pages                    = {81--89},
  Volume                   = {2},

  Doi                      = {10.11003/JKGS.2013.2.1.081},
  ISSN                     = {2288-8187},
  Keywords                 = {1-point method,Ackermann's principle,Bundle Adjustment,kpubs,kpubs.org,rotation estimation},
  Publisher                = {The Korean GNSS Society},
  Url                      = {http://koreascience.or.kr/journal/view.jsp?kj=HOHSB0{\&}py=2013{\&}vnc=v2n1{\&}sp=81}
}

@InProceedings{nie2012camera,
  Title                    = {Camera and lidar fusion for road intersection detection},
  Author                   = {Nie, Yiming and Chen, Qingyang and Chen, Tongtong and Sun, Zhenping and Dai, Bin},
  Booktitle                = {Electrical \& Electronics Engineering (EEESYM), 2012 IEEE Symposium on},
  Year                     = {2012},
  Organization             = {IEEE},
  Pages                    = {273--276}
}

@Article{ozgunalp2017multiple,
  Title                    = {Multiple lane detection algorithm based on novel dense vanishing point estimation},
  Author                   = {Ozgunalp, Umar and Fan, Rui and Ai, Xiao and Dahnoun, Naim},
  Journal                  = {IEEE Transactions on Intelligent Transportation Systems},
  Year                     = {2017},
  Number                   = {3},
  Pages                    = {621--632},
  Volume                   = {18},

  Publisher                = {IEEE}
}

@Article{Reina2015,
  Title                    = {Radar sensing for intelligent vehicles in urban environments},
  Author                   = {Reina, Giulio and Johnson, David and Underwood, James},
  Journal                  = {Sensors (Switzerland)},
  Year                     = {2015},

  Month                    = {jun},
  Number                   = {6},
  Pages                    = {14661--14678},
  Volume                   = {15},

  Abstract                 = {Radar overcomes the shortcomings of laser, stereovision, and sonar because it can operate successfully in dusty, foggy, blizzard-blinding, and poorly lit scenarios. This paper presents a novel method for ground and obstacle segmentation based on radar sensing. The algorithm operates directly in the sensor frame, without the need for a separate synchronised navigation source, calibration parameters describing the location of the radar in the vehicle frame, or the geometric restrictions made in the previous main method in the field. Experimental results are presented in various urban scenarios to validate this approach, showing its potential applicability for advanced driving assistance systems and autonomous vehicle operations.},
  Doi                      = {10.3390/s150614661},
  File                     = {:D$\backslash$:/Users/109123/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Reina, Johnson, Underwood - 2015 - Radar Sensing for Intelligent Vehicles in Urban Environments.pdf:pdf},
  ISSN                     = {14248220},
  Keywords                 = {Navigation systems,Perception in urban environment,Radar sensing,Robotic intelligent vehicles,Unmanned ground vehicles},
  Publisher                = {Multidisciplinary Digital Publishing Institute},
  Url                      = {http://www.mdpi.com/1424-8220/15/6/14661/}
}

@Article{Santana2016,
  Title                    = {Learning a Driving Simulator},
  Author                   = {Santana, Eder and Hotz, George},
  Year                     = {2016},

  Month                    = {aug},

  Abstract                 = {Comma.ai's approach to Artificial Intelligence for self-driving cars is based on an agent that learns to clone driver behaviors and plans maneuvers by simulating future events in the road. This paper illustrates one of our research approaches for driving simulation. One where we learn to simulate. Here we investigate variational autoencoders with classical and learned cost functions using generative adversarial networks for embedding road frames. Afterwards, we learn a transition model in the embedded space using action conditioned Recurrent Neural Networks. We show that our approach can keep predicting realistic looking video for several frames despite the transition model being optimized without a cost function in the pixel space.},
  Archiveprefix            = {arXiv},
  Arxivid                  = {1608.01230},
  Eprint                   = {1608.01230},
  File                     = {:D$\backslash$:/Users/109123/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Santana, Hotz - 2016 - Learning a Driving Simulator.pdf:pdf},
  Url                      = {http://arxiv.org/abs/1608.01230}
}

@Article{Scaramuzza2008,
  Title                    = {Appearance-Guided Monocular Omnidirectional Visual Odometry for Outdoor Ground Vehicles},
  Author                   = {Scaramuzza, D. and Siegwart, R.},
  Journal                  = {IEEE Transactions on Robotics},
  Year                     = {2008},

  Month                    = {oct},
  Number                   = {5},
  Pages                    = {1015--1026},
  Volume                   = {24},

  Doi                      = {10.1109/TRO.2008.2004490},
  ISSN                     = {1552-3098},
  Url                      = {http://ieeexplore.ieee.org/document/4625958/}
}

@InProceedings{schreiber2013laneloc,
  Title                    = {Laneloc: Lane marking based localization using highly accurate maps},
  Author                   = {Schreiber, Markus and Kn{\"o}ppel, Carsten and Franke, Uwe},
  Booktitle                = {Intelligent Vehicles Symposium (IV), 2013 IEEE},
  Year                     = {2013},
  Organization             = {IEEE},
  Pages                    = {449--454}
}

@Article{soilan2016traffic,
  Title                    = {Traffic sign detection in MLS acquired point clouds for geometric and image-based semantic inventory},
  Author                   = {Soil{\'a}n, Mario and Riveiro, Bel{\'e}n and Mart{\'\i}nez-S{\'a}nchez, Joaqu{\'\i}n and Arias, Pedro},
  Journal                  = {ISPRS Journal of Photogrammetry and Remote Sensing},
  Year                     = {2016},
  Pages                    = {92--101},
  Volume                   = {114},

  Publisher                = {Elsevier}
}

@InProceedings{Stein2003,
  Title                    = {Vision-based ACC with a single camera: Bounds on range and range rate accuracy},
  Author                   = {Stein, Gideon P. and Mano, Ofer and Shashua, Amnon},
  Booktitle                = {IEEE Intelligent Vehicles Symposium, Proceedings},
  Year                     = {2003},
  Pages                    = {120--125},
  Publisher                = {IEEE},

  Abstract                 = {This paper describes a vision-based adaptive cruise control (ACC) system which uses a single camera as input. In particular, we discuss how to compute the range and range-rate from a single camera and discuss how the imaging geometry affects the range and range rate accuracy. We determine the bound on the accuracy given a particular configuration. These bounds in turn determine what steps must be made to achieve good performance. The system has been implemented on a test vehicle and driven on various highways over thousands of miles.},
  Doi                      = {10.1109/IVS.2003.1212895},
  ISBN                     = {0780378482},
  Url                      = {http://ieeexplore.ieee.org/document/1212895/}
}

@Article{sun2014application,
  Title                    = {Application of BW-ELM model on traffic sign recognition},
  Author                   = {Sun, Zhan-Li and Wang, Han and Lau, Wai-Shing and Seet, Gerald and Wang, Danwei},
  Journal                  = {Neurocomputing},
  Year                     = {2014},
  Pages                    = {153--159},
  Volume                   = {128},

  Publisher                = {Elsevier}
}

@Article{tan2016weakly,
  Title                    = {Weakly supervised metric learning for traffic sign recognition in a LIDAR-equipped vehicle},
  Author                   = {Tan, Min and Wang, Baoyuan and Wu, Zhaohui and Wang, Jingdong and Pan, Gang},
  Journal                  = {IEEE Transactions on Intelligent Transportation Systems},
  Year                     = {2016},
  Number                   = {5},
  Pages                    = {1415--1427},
  Volume                   = {17},

  Publisher                = {IEEE}
}

@Article{timofte2014multi,
  Title                    = {Multi-view traffic sign detection, recognition, and 3d localisation},
  Author                   = {Timofte, Radu and Zimmermann, Karel and Van Gool, Luc},
  Journal                  = {Machine vision and applications},
  Year                     = {2014},
  Number                   = {3},
  Pages                    = {633--647},
  Volume                   = {25},

  Publisher                = {Springer}
}

@Article{villalon2017traffic,
  Title                    = {Traffic sign detection system for locating road intersections and roundabouts: the Chilean case},
  Author                   = {Villal{\'o}n-Sep{\'u}lveda, Gabriel and Torres-Torriti, Miguel and Flores-Calero, Marco},
  Journal                  = {Sensors},
  Year                     = {2017},
  Number                   = {6},
  Pages                    = {1207},
  Volume                   = {17},

  Publisher                = {Multidisciplinary Digital Publishing Institute}
}

@Article{wali2015automatic,
  Title                    = {An automatic traffic sign detection and recognition system based on colour segmentation, shape matching, and svm},
  Author                   = {Wali, Safat B and Hannan, Mahammad A and Hussain, Aini and Samad, Salina A},
  Journal                  = {Mathematical Problems in Engineering},
  Year                     = {2015},
  Volume                   = {2015},

  Publisher                = {Hindawi}
}

@InProceedings{weng2016road,
  Title                    = {Road traffic sign detection and classification from mobile LiDAR point clouds},
  Author                   = {Weng, Shengxia and Li, Jonathan and Chen, Yiping and Wang, Cheng},
  Booktitle                = {2nd ISPRS International Conference on Computer Vision in Remote Sensing (CVRS 2015)},
  Year                     = {2016},
  Organization             = {International Society for Optics and Photonics},
  Pages                    = {99010A},
  Volume                   = {9901}
}

@Article{yang2012automated,
  Title                    = {Automated extraction of road markings from mobile LiDAR point clouds},
  Author                   = {Yang, Bisheng and Fang, Lina and Li, Qingquan and Li, Jonathan},
  Journal                  = {Photogrammetric Engineering \& Remote Sensing},
  Year                     = {2012},
  Number                   = {4},
  Pages                    = {331--338},
  Volume                   = {78},

  Publisher                = {American Society for Photogrammetry and Remote Sensing}
}

@Article{yang2016towards,
  Title                    = {Towards real-time traffic sign detection and classification},
  Author                   = {Yang, Yi and Luo, Hengliang and Xu, Huarong and Wu, Fuchao},
  Journal                  = {IEEE Transactions on Intelligent Transportation Systems},
  Year                     = {2016},
  Number                   = {7},
  Pages                    = {2022--2031},
  Volume                   = {17},

  Publisher                = {IEEE}
}

@Article{Yebes2015,
  Title                    = {Visual Object Recognition with 3D-Aware Features in KITTI Urban Scenes},
  Author                   = {Yebes, J. Javier and Bergasa, Luis M. and Garc{\'{i}}a-Garrido, Miguel {\'{A}}ngel},
  Journal                  = {Sensors (Basel, Switzerland)},
  Year                     = {2015},

  Month                    = {apr},
  Number                   = {4},
  Pages                    = {9228--9250},
  Volume                   = {15},

  Abstract                 = {Driver assistance systems and autonomous robotics rely on the deployment of several sensors for environment perception. Compared to LiDAR systems, the inexpensive vision sensors can capture the 3D scene as perceived by a driver in terms of appearance and depth cues. Indeed, providing 3D image understanding capabilities to vehicles is an essential target in order to infer scene semantics in urban environments. One of the challenges that arises from the navigation task in naturalistic urban scenarios is the detection of road participants (e.g., cyclists, pedestrians and vehicles). In this regard, this paper tackles the detection and orientation estimation of cars, pedestrians and cyclists, employing the challenging and naturalistic KITTI images. This work proposes 3D-aware features computed from stereo color images in order to capture the appearance and depth peculiarities of the objects in road scenes. The successful part-based object detector, known as DPM, is extended to learn richer models from the 2.5D data (color and disparity), while also carrying out a detailed analysis of the training pipeline. A large set of experiments evaluate the proposals, and the best performing approach is ranked on the KITTI website. Indeed, this is the first work that reports results with stereo data for the KITTI object challenge, achieving increased detection ratios for the classes car and cyclist compared to a baseline DPM.},
  Doi                      = {10.3390/s150409228},
  ISBN                     = {14248220},
  ISSN                     = {14248220},
  Keywords                 = {2.5D},
  Mendeley-tags            = {2.5D},
  Pmid                     = {102279770},
  Url                      = {http://www.ncbi.nlm.nih.gov/pubmed/25903553 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4431302 http://www.mdpi.com/1424-8220/15/4/9228/}
}

@Article{zaklouta2014real,
  Title                    = {Real-time traffic sign recognition in three stages},
  Author                   = {Zaklouta, Fatin and Stanciulescu, Bogdan},
  Journal                  = {Robotics and autonomous systems},
  Year                     = {2014},
  Number                   = {1},
  Pages                    = {16--24},
  Volume                   = {62},

  Publisher                = {Elsevier}
}

@PhdThesis{Zhang2016,
  Title                    = {Rapid Inspection of Pavement Markings Using Mobile Laser Scanning Point Clouds},
  Author                   = {Zhang, Haocheng},
  School                   = {University of Waterloo},
  Year                     = {2016},
  Month                    = {mar},

  File                     = {:D$\backslash$:/Users/109123/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang - 2016 - Rapid Inspection of Pavement Markings Using Mobile Laser Scanning Point Clouds.pdf:pdf},
  Url                      = {https://uwspace.uwaterloo.ca/handle/10012/10343}
}

@Article{zhang2017real,
  Title                    = {A Real-Time Chinese Traffic Sign Detection Algorithm Based on Modified YOLOv2},
  Author                   = {Zhang, Jianming and Huang, Manting and Jin, Xiaokang and Li, Xudong},
  Journal                  = {Algorithms},
  Year                     = {2017},
  Number                   = {4},
  Pages                    = {127},
  Volume                   = {10},

  Publisher                = {Multidisciplinary Digital Publishing Institute}
}

@InProceedings{zhao2012curb,
  Title                    = {Curb detection and tracking using 3D-LIDAR scanner},
  Author                   = {Zhao, Gangqiang and Yuan, Junsong},
  Booktitle                = {Image Processing (ICIP), 2012 19th IEEE International Conference on},
  Year                     = {2012},
  Organization             = {IEEE},
  Pages                    = {437--440}
}

@InProceedings{zhou2014lidar,
  Title                    = {LIDAR and vision-based real-time traffic sign detection and recognition algorithm for intelligent vehicle},
  Author                   = {Zhou, Lipu and Deng, Zhidong},
  Booktitle                = {Intelligent Transportation Systems (ITSC), 2014 IEEE 17th International Conference on},
  Year                     = {2014},
  Organization             = {IEEE},
  Pages                    = {578--583}
}

